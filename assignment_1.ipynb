{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Assignment 1: Pose classification with naive Bayes\n",
    "\n",
    "###### Submission deadline: 7 pm, Tuesday 6 Apr 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s):**     `PLEASE ENTER YOUR ID(S) HERE`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "\n",
    "def preprocess(train_path, test_path):\n",
    "    headers = ['Pose', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'y1', 'y2', 'y3', 'y4', 'y5', 'y6', 'y7', 'y8', 'y9', 'y10', 'y11']\n",
    "    df_train = pd.read_csv(train_path, names=headers)\n",
    "    df_test = pd.read_csv(test_path, names=headers)\n",
    "\n",
    "    # replace 9999 with NaN for further processing\n",
    "    df_train = df_train.replace([9999], np.nan)\n",
    "    df_test = df_test.replace([9999], np.nan)\n",
    "\n",
    "    '''Dealing with NaN values'''\n",
    "    # For train data\n",
    "    # filling missing values by median in each group (retain skewness)\n",
    "    f = lambda x: x.median() if np.issubdtype(x.dtype, np.number) else x.mode().iloc[0]\n",
    "    df_train = df_train.fillna(df_train.groupby('Pose').transform(f))\n",
    "\n",
    "    # For test data\n",
    "    # filling missing values by median of the whole dataset\n",
    "    df_test = df_test.fillna(df_test.median())\n",
    "    df_test = np.array(df_test)\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "\n",
    "df_train, df_test = preprocess(train_path, test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should calculate prior probabilities and likelihoods from the training data and usingthem to build a naive Bayes model\n",
    "\n",
    "def train():\n",
    "    # get all concepts(poses) as a list\n",
    "    poses = list(df_train['Pose'].value_counts().index)\n",
    "\n",
    "    # calculate statistics in training dataset\n",
    "    pose_dict = dict()\n",
    "    for pose in poses:\n",
    "        pb_c = df_train.groupby('Pose').size()[pose] / len(df_train) # get prior probabilities\n",
    "        pose_dict[pose] = np.array([pb_c, df_train[df_train['Pose'] == pose].describe().iloc[[1,2]].values], dtype=object) # get mean & stdv for all x and y (from 1 to 11)\n",
    "\n",
    "    return pose_dict\n",
    "\n",
    "\n",
    "\n",
    "pose_dict = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "      <th>y11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.007176</td>\n",
       "      <td>-0.108334</td>\n",
       "      <td>-43.016699</td>\n",
       "      <td>-50.895127</td>\n",
       "      <td>43.169189</td>\n",
       "      <td>51.108017</td>\n",
       "      <td>-0.150617</td>\n",
       "      <td>-16.732309</td>\n",
       "      <td>-13.959189</td>\n",
       "      <td>16.623688</td>\n",
       "      <td>...</td>\n",
       "      <td>109.927956</td>\n",
       "      <td>64.608528</td>\n",
       "      <td>29.111031</td>\n",
       "      <td>64.743256</td>\n",
       "      <td>28.939961</td>\n",
       "      <td>9.954995</td>\n",
       "      <td>-72.358276</td>\n",
       "      <td>-159.434010</td>\n",
       "      <td>-72.369811</td>\n",
       "      <td>-159.565578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.942956</td>\n",
       "      <td>2.257785</td>\n",
       "      <td>7.989678</td>\n",
       "      <td>18.969064</td>\n",
       "      <td>7.970678</td>\n",
       "      <td>19.072963</td>\n",
       "      <td>1.330744</td>\n",
       "      <td>3.742915</td>\n",
       "      <td>7.174475</td>\n",
       "      <td>3.709626</td>\n",
       "      <td>...</td>\n",
       "      <td>16.102933</td>\n",
       "      <td>15.385883</td>\n",
       "      <td>42.705678</td>\n",
       "      <td>15.185203</td>\n",
       "      <td>42.133322</td>\n",
       "      <td>16.103028</td>\n",
       "      <td>16.110207</td>\n",
       "      <td>17.872827</td>\n",
       "      <td>16.025912</td>\n",
       "      <td>17.942485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        x2         x3         x4         x5         x6  \\\n",
       "mean -0.007176 -0.108334 -43.016699 -50.895127  43.169189  51.108017   \n",
       "std   2.942956  2.257785   7.989678  18.969064   7.970678  19.072963   \n",
       "\n",
       "            x7         x8         x9        x10  ...          y2         y3  \\\n",
       "mean -0.150617 -16.732309 -13.959189  16.623688  ...  109.927956  64.608528   \n",
       "std   1.330744   3.742915   7.174475   3.709626  ...   16.102933  15.385883   \n",
       "\n",
       "             y4         y5         y6         y7         y8          y9  \\\n",
       "mean  29.111031  64.743256  28.939961   9.954995 -72.358276 -159.434010   \n",
       "std   42.705678  15.185203  42.133322  16.103028  16.110207   17.872827   \n",
       "\n",
       "            y10         y11  \n",
       "mean -72.369811 -159.565578  \n",
       "std   16.025912   17.942485  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['Pose'] == 'mountain'].describe().iloc[[1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.214190093708166,\n",
       "       array([[-7.17589375e-03, -1.08333981e-01, -4.30166994e+01,\n",
       "        -5.08951269e+01,  4.31691888e+01,  5.11080169e+01,\n",
       "        -1.50617486e-01, -1.67323087e+01, -1.39591893e+01,\n",
       "         1.66236881e+01,  1.39685612e+01,  1.56441937e+02,\n",
       "         1.09927956e+02,  6.46085281e+01,  2.91110312e+01,\n",
       "         6.47432563e+01,  2.89399613e+01,  9.95499481e+00,\n",
       "        -7.23582756e+01, -1.59434010e+02, -7.23698113e+01,\n",
       "        -1.59565578e+02],\n",
       "       [ 2.94295594e+00,  2.25778535e+00,  7.98967825e+00,\n",
       "         1.89690637e+01,  7.97067830e+00,  1.90729632e+01,\n",
       "         1.33074412e+00,  3.74291500e+00,  7.17447538e+00,\n",
       "         3.70962646e+00,  6.98133847e+00,  1.95825884e+01,\n",
       "         1.61029329e+01,  1.53858832e+01,  4.27056775e+01,\n",
       "         1.51852034e+01,  4.21333225e+01,  1.61030279e+01,\n",
       "         1.61102068e+01,  1.78728270e+01,  1.60259117e+01,\n",
       "         1.79424848e+01]])], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_dict['mountain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should predict classes for new items in a test dataset (for the purposes of this assignment, you can re-use the training data as a test set)\n",
    "\n",
    "def calc_phi(x, mu, sigma):\n",
    "    # return the likelihood of feature x_i in class c\n",
    "    phi = 1 / (sigma * np.sqrt(2 * np.pi)) * np.e ** (- 1 / 2 * ((x - mu) / sigma) ** 2)\n",
    "\n",
    "    # smoothing (but accuracy doesnt change tho)\n",
    "    if phi == 0:\n",
    "        phi = 0.000000001\n",
    "    return phi\n",
    "\n",
    "def predict():\n",
    "    results = list()\n",
    "    for instance in df_test:\n",
    "        # prob_dict to store all the probabilities (log form) for comparison later\n",
    "        prob_dict = dict()\n",
    "        features = instance[1:] # remove concept\n",
    "        for pose in pose_dict:\n",
    "            prob_sum = 0\n",
    "            pb_c = pose_dict[pose][0] # Prior probability of class c_j\n",
    "            prob_sum += np.log(pb_c)\n",
    "            for i in range(len(features)):\n",
    "                x = features[i] # data x of feature x_i\n",
    "                mu = pose_dict[pose][1][0][i] # mean of feature x_i\n",
    "                sigma = pose_dict[pose][1][1][i] # stf of feature x_i\n",
    "                pb_x_c = pb_c * calc_phi(x, mu, sigma) \n",
    "                prob_sum += np.log(pb_x_c)\n",
    "            prob_dict[pose] = prob_sum\n",
    "        predicted = max(prob_dict, key = prob_dict.get) # choose the highest value as predicted result\n",
    "        actual = instance[0]\n",
    "        results.append([predicted, actual])\n",
    "\n",
    "    return results\n",
    "\n",
    "results = predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5258620689655172\n"
     ]
    }
   ],
   "source": [
    "# This function should evaliate the prediction performance by comparing your model’s class outputs to ground truth labels\n",
    "\n",
    "def evaluate():\n",
    "    t = 0\n",
    "    n = len(results)\n",
    "    for predicted, actual in results:\n",
    "        if predicted == actual:\n",
    "            t += 1\n",
    "\n",
    "    accuracy = t / n\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "accuracy = evaluate()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mountain': {'mountain': 27,\n",
       "  'downwarddog': 3,\n",
       "  'bridge': 1,\n",
       "  'childs': 1,\n",
       "  'tree': 0,\n",
       "  'trianglepose': 0,\n",
       "  'plank': 0,\n",
       "  'warrior2': 0,\n",
       "  'warrior1': 0,\n",
       "  'seatedforwardbend': 0},\n",
       " 'downwarddog': {'mountain': 0,\n",
       "  'downwarddog': 3,\n",
       "  'bridge': 0,\n",
       "  'childs': 3,\n",
       "  'tree': 0,\n",
       "  'trianglepose': 0,\n",
       "  'plank': 3,\n",
       "  'warrior2': 0,\n",
       "  'warrior1': 0,\n",
       "  'seatedforwardbend': 0},\n",
       " 'bridge': {'mountain': 0,\n",
       "  'downwarddog': 1,\n",
       "  'bridge': 8,\n",
       "  'childs': 0,\n",
       "  'tree': 0,\n",
       "  'trianglepose': 0,\n",
       "  'plank': 2,\n",
       "  'warrior2': 0,\n",
       "  'warrior1': 0,\n",
       "  'seatedforwardbend': 1},\n",
       " 'childs': {'mountain': 0,\n",
       "  'downwarddog': 0,\n",
       "  'bridge': 0,\n",
       "  'childs': 0,\n",
       "  'tree': 0,\n",
       "  'trianglepose': 0,\n",
       "  'plank': 0,\n",
       "  'warrior2': 0,\n",
       "  'warrior1': 0,\n",
       "  'seatedforwardbend': 0},\n",
       " 'tree': {'mountain': 3,\n",
       "  'downwarddog': 0,\n",
       "  'bridge': 0,\n",
       "  'childs': 0,\n",
       "  'tree': 6,\n",
       "  'trianglepose': 0,\n",
       "  'plank': 0,\n",
       "  'warrior2': 1,\n",
       "  'warrior1': 0,\n",
       "  'seatedforwardbend': 0},\n",
       " 'trianglepose': {'mountain': 0,\n",
       "  'downwarddog': 5,\n",
       "  'bridge': 2,\n",
       "  'childs': 6,\n",
       "  'tree': 0,\n",
       "  'trianglepose': 4,\n",
       "  'plank': 3,\n",
       "  'warrior2': 0,\n",
       "  'warrior1': 0,\n",
       "  'seatedforwardbend': 7},\n",
       " 'plank': {'mountain': 0,\n",
       "  'downwarddog': 6,\n",
       "  'bridge': 3,\n",
       "  'childs': 3,\n",
       "  'tree': 0,\n",
       "  'trianglepose': 0,\n",
       "  'plank': 1,\n",
       "  'warrior2': 0,\n",
       "  'warrior1': 1,\n",
       "  'seatedforwardbend': 0},\n",
       " 'warrior2': {'mountain': 0,\n",
       "  'downwarddog': 0,\n",
       "  'bridge': 0,\n",
       "  'childs': 0,\n",
       "  'tree': 0,\n",
       "  'trianglepose': 0,\n",
       "  'plank': 0,\n",
       "  'warrior2': 7,\n",
       "  'warrior1': 0,\n",
       "  'seatedforwardbend': 0},\n",
       " 'warrior1': {'mountain': 0,\n",
       "  'downwarddog': 0,\n",
       "  'bridge': 0,\n",
       "  'childs': 0,\n",
       "  'tree': 0,\n",
       "  'trianglepose': 0,\n",
       "  'plank': 0,\n",
       "  'warrior2': 0,\n",
       "  'warrior1': 4,\n",
       "  'seatedforwardbend': 0},\n",
       " 'seatedforwardbend': {'mountain': 0,\n",
       "  'downwarddog': 0,\n",
       "  'bridge': 0,\n",
       "  'childs': 0,\n",
       "  'tree': 0,\n",
       "  'trianglepose': 0,\n",
       "  'plank': 0,\n",
       "  'warrior2': 0,\n",
       "  'warrior1': 0,\n",
       "  'seatedforwardbend': 1}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {key: {key: 0 for key in list(pose_dict.keys())} for key in list(pose_dict.keys())}\n",
    "for predicted, actual in results:\n",
    "    d[predicted][actual] += 1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mountain', 'downwarddog', 'bridge', 'childs', 'tree', 'trianglepose', 'plank', 'warrior1', 'warrior2', 'seatedforwardbend']\n"
     ]
    }
   ],
   "source": [
    "print(poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  0,  0,  0,  3,  0,  0,  0,  0,  0],\n",
       "       [ 3,  3,  1,  0,  0,  5,  6,  0,  0,  0],\n",
       "       [ 1,  0,  8,  0,  0,  2,  3,  0,  0,  0],\n",
       "       [ 1,  3,  0,  0,  0,  6,  3,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  6,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  4,  0,  0,  0,  0],\n",
       "       [ 0,  3,  2,  0,  0,  3,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1,  4,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  0,  7,  0],\n",
       "       [ 0,  0,  1,  0,  0,  7,  0,  0,  0,  1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "poses = list(pose_dict.keys())\n",
    "p = list()\n",
    "a = list()\n",
    "for predicted, actual in results:\n",
    "    p.append(predicted)\n",
    "    a.append(actual)\n",
    "\n",
    "confusion_matrix(a, p, labels=poses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to **two** questions of your choosing.\n",
    "\n",
    "If you are in a group of 2, you will respond to **four** questions of your choosing.\n",
    "\n",
    "A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer should be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Since this is a multiclass classification problem, there are multiple ways to compute precision, recall, and F-score for this classifier. Implement at least two of the methods from the \"Model Evaluation\" lecture and discuss any differences between them. (The implementation should be your own and should not just call a pre-existing function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pose_dict_index = dict()\n",
    "i= 0\n",
    "pose_num = len(set(pose_dict))\n",
    "# mark each pose as an integer index\n",
    "for pose in set(pose_dict):\n",
    "    pose_dict_index[pose]=i\n",
    "    i+=1\n",
    "pose_dict_index\n",
    "\n",
    "# calculate confusion matrix\n",
    "m_eval = np.zeros((pose_num,pose_num),dtype = int)\n",
    "for predicted,actual in results:\n",
    "    m_eval[pose_dict_index[predicted]][pose_dict_index[actual]]+=1\n",
    "\n",
    "TP = np.zeros((1,pose_num))\n",
    "FP = np.zeros((1,pose_num))\n",
    "FN = np.zeros((1,pose_num))\n",
    "precision_array = np.zeros((1,pose_num))\n",
    "recall_array = np.zeros((1,pose_num))\n",
    "for i in range(pose_num):\n",
    "    tp = m_eval[i][i]                                               #tp value\n",
    "    fp = sum(m_eval[i][j] for j in range(pose_num) if not j == i)   #fp value\n",
    "    fn = sum(m_eval[j][i] for j in range(pose_num) if not j == i)   #fn value\n",
    "    # Macro-averaging\n",
    "    TP[0][i]=tp\n",
    "    FP[0][i]=fp\n",
    "    FN[0][i]=fn\n",
    "    precision_array[0][i] = tp/(tp+fp) if not tp +fp ==0 else 0          \n",
    "    recall_array[0][i] = tp/(tp+fn) if not tp +fn ==0 else 0\n",
    "\n",
    "precision_macro = precision_array.mean()\n",
    "recall_macro = recall_array.mean()\n",
    "\n",
    "# Micro-averaging\n",
    "precision_micro  = TP.sum()/(TP.sum()+FP.sum())\n",
    "recall_micro = TP.sum()/(TP.sum()+FN.sum())\n",
    "print(\"Precision with Macro-averaging: \",precision_macro.mean())\n",
    "print(\"Recall with Macro-averaging: \",recall_macro.mean())\n",
    "print(\"F-score with Macro-averaging:\" , 2*precision_macro*recall_macro/(precision_macro+recall_macro))\n",
    "print(\"Precision with Micro-averagin: \", precision_micro)\n",
    "print(\"Recall with Micro-averagin: \", recall_micro)\n",
    "print(\"F-score with Micro-averaging:\" , 2*precision_micro*recall_micro/(precision_micro+recall_micro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "The Gaussian naıve Bayes classifier assumes that numeric attributes come from a Gaussian distribution. Is this assumption always true for the numeric attributes in this dataset? Identify some cases where the Gaussian assumption is violated and describe any evidence (or lack thereof) that this has some effect on the classifier’s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Implement a kernel density estimate (KDE) naive Bayes classifier and compare its performance to the Gaussian naive Bayes classifier. Recall that KDE has kernel bandwidth as a free parameter -- you can choose an arbitrary value for this, but a value in the range 5-25 is recommended. Discuss any differences you observe between the Gaussian and KDE naive Bayes classifiers. (As with the Gaussian naive Bayes, this KDE naive Bayes implementation should be your own and should not just call a pre-existing function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# get all concepts(poses) as a list\n",
    "poses = list(df_train['Pose'].value_counts().index)\n",
    "\n",
    "# calculate statistics in training dataset\n",
    "pb_c_dict = dict()\n",
    "for pose in poses:\n",
    "    pb_c_dict[pose] = df_train.groupby('Pose').size()[pose] / len(df_train)\n",
    "\n",
    "\n",
    "pose_kde_dict = dict()\n",
    "\n",
    "SIGMA = 5\n",
    "# df_test as np array\n",
    "results = list()\n",
    "for instance in df_test:\n",
    "        # prob_dict to store all the probabilities (log form) for comparison later\n",
    "        prob_dict = dict()\n",
    "        features = instance[1:] # remove concept\n",
    "        for pose in poses:\n",
    "            prob_sum = 0\n",
    "            pb_c = pb_c_dict[pose] # prior probability of class c_j\n",
    "            prob_sum += np.log(pb_c)\n",
    "\n",
    "            for i in range(len(features)):\n",
    "                xi_array = np.array(df_train[df_train['Pose'] == pose].drop(['Pose'], axis=1).iloc[:,i]) # get instance of test set\n",
    "                x_test = features[i] # data x of feature x_i as x_test\n",
    "                phi = 0\n",
    "                for j in range(len(df_train)):\n",
    "                    xi = xi_array[i]\n",
    "                    phi += calc_phi(x_test, xi, SIGMA) \n",
    "                phi = phi / len(df_train)\n",
    "                prob_sum += np.log(phi)\n",
    "\n",
    "            prob_dict[pose] = prob_sum\n",
    "\n",
    "        predicted = max(prob_dict, key = prob_dict.get) # choose the highest value as predicted result\n",
    "        actual = instance[0]\n",
    "        results.append([predicted, actual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3793103448275862"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0\n",
    "n = len(results)\n",
    "for predicted, actual in results:\n",
    "    if predicted == actual:\n",
    "        t += 1\n",
    "\n",
    "accuracy = t / n\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "Instead of using an arbitrary kernel bandwidth for the KDE naive Bayes classifier, use random hold-out or cross-validation to choose the kernel bandwidth. Discuss how this changes the model performance compared to using an arbitrary kernel bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "Naive Bayes ignores missing values, but in pose recognition tasks the missing values can be informative. Missing values indicate that some part of the body was obscured and sometimes this is relevant to the pose (e.g., holding one hand behind the back). Are missing values useful for this task? Implement a method that incorporates information about missing values and demonstrate whether it changes the classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "Engineer your own pose features from the provided keypoints. Instead of using the (x,y) positions of keypoints, you might consider the angles of the limbs or body, or the distances between pairs of keypoints. How does a naive Bayes classifier based on your engineered features compare to the classifier using (x,y) values? Please note that we are interested in explainable features for pose recognition, so simply putting the (x,y) values in a neural network or similar to get an arbitrary embedding will not receive full credit for this question. You should be able to explain the rationale behind your proposed features. Also, don't forget the conditional independence assumption of naive Bayes when proposing new features -- a large set of highly-correlated features may not work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
